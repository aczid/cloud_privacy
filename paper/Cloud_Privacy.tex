\documentclass[11pt]{article}
\usepackage{enumitem}
\usepackage{listings}
\usepackage{color}
\usepackage{tabularx}

\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{sidecap}
\usepackage{epstopdf}

\usepackage{amsmath}

%\def\bibfont{\scriptsize}

\usepackage{natbib}
\setlength{\bibsep}{0.0pt}

\newcommand{\op}[1]{\operatorname{#1}}

\begin{document}
\title{Privacy in Cloud Computing}

\author{Erik Boss \and Aram Verstegen}
%\institute{Radboud Universiteit Nijmegen}
\date{\today}
\maketitle

\abstract{We summarize our concerns for observed and potential privacy risks associated with cloud computing in a broad sense, subsequently review the legal aspects concerning data protection from a European perspective, followed by a summary of two related and applicable privacy-enhancing technologies uncovered in our literature study, and conclude by reflecting on the state of affairs.}
% TODO rewrite...

\section{Introduction}
In recent years there has been a lot of positive buzz surrounding the idea of \textit{cloud computing}: a systems design trend that allows applications to run as ubiquitous services by providing abstractions to the lower layers of application architecture.
These layers can be distinguished as \textit{Software}, \textit{Platform} and \textit{Infrastructure} and each of these has a different target audience which can buy these facilities ``as a service'', i.e., Software/Platform/Infrastructure as a Service (SaaS, PaaS, IaaS). 
Such abstractions bring benefits like implicit redundancy, centralized security measures and, most importantly, reduces capital and operational expenses for customers by the increased efficiency at which each layer can be managed.

That being said, there is also a note of concern with things like centralized information management, giving up physical segregation for logical segregation, near-infinite storage capacity, cheap, ubiquitous computing power and the legal issues surrounding information processing systems whose infrastructure scale transcends national borders.

In cloud computing it's apparent that there is a very strong connection between security and privacy.
If any central component of cloud infrastructure were to be compromised it could almost certainly be used to disclose very privacy-sensitive information, given the scale of cloud infrastructure providers and what kind of private information is (or can be) recorded using applications running ``in the cloud''.
In fact, there is no proof or technically feasible way to prove that such a compromise has not occurred already.

Some of these issues culminate in the recently much-publicised case of mass surveillance by the United States National Security Agency and its overseas partners.
As more facts on this case are being made public we are better equipped to make informed choices in how we interact with the manifestations of this technology trend.
We no longer need speculation on a worst-case estimate alone to build our adversary model, we now have concrete evidence that our data privacy and computational privacy are at risk.

In this article we will go over some of the potential and actual privacy-related problems that we have encountered as part of our study on the technical and legal domains of cloud computing. Starting off, in \autoref{sec:problems_in_cloud_computing} we give a fairly broad overview of the privacy-related issues encountered within the cloud computing era.
This will lead into an analysis of the current legal situation regarding cloud computing from a local perspective in \autoref{sec:legal_analysis}. In \autoref{sec:pet} we will go over the technical details and specifically describe some of the solutions to privacy-related problems in cloud computing by means of Privacy Enhancing Techologies (PETs). Finally we reflect on our findings and give concluding remarks in \autoref{sec:conclusion}.

\section{Privacy problems in cloud computing}
\label{sec:problems_in_cloud_computing}
%General concerns with cloud security: centralisation, single point of failure, corporate espionage, subpoenas to the provider, impact of security compromises
%In the multi-layered design of cloud-based infrastructure our privacy concerns are mostly contained within individual layers.

While centralization of infrastructure should generally imply better basic physical and network security, it may lead to greater fragility of the networked ecosystem as a whole, whereby attacks have greater impact than in a strictly distributed environment.
Consider how acts of observation, manipulation or destruction would be more effective when carried out against the central node in a star-shaped network rather than anywhere in a well-connected network.
There exists more redundancy in the more connected network, which helps make the infrastructure more robust against any such disruptions.
%For a trustworthy internet we want to have more connection points into the network than the adversary can conceivably take over.
%Some systems may appear to be more (logically) distributed than they actually (physically) are. 

\subsection{Third Parties}
It seems to us the main privacy problem with the cloud paradigm is the trend all but forces users to relinquish control of previously self-hosted information to fewer and fewer third parties.
%The infrastructure layer is at the bottom of the application stack, with platform and service layers respectively building upon that foundation.
The competitive advantage achieved with scale allows a few key players to lead the Cloud market with an overwhelming majority.
The IaaS market is dominated by Amazon who have a 35\% market share, their closest competitor is IBM with only a 5\% share.
PaaS seems to be a more competitive field, with the top three players Salesforce, Amazon and Microsoft each taking roughly 15\% of the market.
% TODO Cite http://www.telegeography.com/products/commsupdate/articles/2013/03/11/amazons-cloud-iaas-and-paas-investments-pay-off/
SaaS is the most diversified layer in the cloud paradigm, the problems we see here are not in market share but in sheer scale.
Large U.S.-based companies like Facebook, Twitter and Google openly construct behavioral profiles of their millions of `users' on behalf of their `clients' - and are severely treading on user privacy in the process.
Google has announced their own `Compute Engine' IaaS service only last year, but we feel they have the capacity to oust Amazon from the leading position in the years to come.

\subsection{Cause for Concern}
Having only a few companies in physical possession of so much personal data is cause for concern in light of the aforementioned fragility that large, centralized information systems are susceptible to with regards to observation, manipulation or destruction of data.
Of course these companies do not have a monolithic infrastructure behind their facade; but insiders, legally mandated government agents and clandestine intruders may (hypothetically) reach far into their systems and attain full access to any information stored there.

In the light of recent revelations related to U.S. surveillance programmes, this appears to be much less hypothetical than we initially assumed.
The expectation of privacy when dealing with such companies not only lacks a factual foundation to begin with, but now even the notional expectation of privacy has been severely diminished.
At the risk of being cynical: the upshot here is that the public's perception of cloud-related privacy matters is more in line with reality now that they are better informed.


\subsection{Computational Privacy?}
%A first step in the right direction is to provide \textit{end-to-end encryption} for data in transit.
We should discern the difference between privacy of \textit{data} and privacy in \textit{computation}.
To illustrate: a data file with private information can be kept secret while hosted in `hostile territory' by means of conventional encryption schemes - provided the general cryptographic caveats like choice of cipher and operation mode, key generation/management/distribution et cetera are properly addressed - but the required encryption operations and the party that applies them must also operate \textit{consistently} for this scheme to be secure.
%The main concern in related research is surrounding data privacy, but we find computational privacy to be of equal or greater concern.
%Remotely hosted applications come with the inherent problem that their behaviour can be more difficult to analyse in order asses their security and privacy safeguards.

Data privacy is something we as computer scientists understand well in terms of secrecy, but computational privacy has actually been dauntingly hard to make sense of to us - we see backdoors \emph{all the way down}.
Whereas with personal computing the integrity of the system can be verified down to the hardware level - systems can be tested to confirm to the specifications using \textit{reverse engineering} methods on hardware and software and this can be validated externally, the cloud environment only allows the most cursory glance at the inner workings.
%offers only a superficial analysis until we hit the Virtual Machine barrier; the VM actually functions as a `black box'.

The problem is exacerbated by the fact that virtualization technologies abstract systems from the hardware layer, and require systems built upon them to similarly trust this technology during computation.
And again there is centralization in these technologies, leading to concerns about (virtually) universal backdoors in all systems built upon a handful of such technologies.

\subsection{Formalisms and Philosophy}
%This means we require trust in providers' ability to adequately handle privacy-sensitive information.
The strength of encryption schemes can be proven in relation to the hardness of a mathematical problem, but we have no analogous formalism at our disposal with which to gauge consistency in who or what performs these algorithms - let alone enforcing \textit{provable} integrity through formal methods in this black box environment.

%Provided we can achieve perfect data privacy using PETs

%TODO Cite http://cryptome.org/2013/08/callas-snowden.htm
John Callas quite recently opined on this matter and lucidly identified it to be a deeply philosophical problem - G\"odel's second incompleteness theorem, which states a system cannot be proven consistent from within that very system.
His response to these problems is then to concede to a system that is simply `good enough'.
We should therefore construct systems that conform to our specifications and employ an \textit{external} verifier system - this is the best we can do and is also the basic premise of the proposed PETs.


%We want to cover either of these two cases:

% Dit heeft eigenlijk niks met cloud privacy te maken... NSLs mogen alleen transactionele data opvragen
%\subsection{Problem case summary: Doe vs Ashcroft}
%In the United States there exists an investigative tool
%An investigative tool for intelligence agencies like the FBI known to be in use since 1978 is the National Security Letter (NSL): a demand letter for transactional records, accompanied by an indefinite gag order forbidding disclosure of the demand.
%Summary of the story of an ISP that got a NSL - and what an NSL actually demands
%\cite{garlinger2009privacy, gorham2008national}

%\subsection{Problem case summary: Cyberlocker raids}
%How cloud providers are being held accountable for the content they host

%\subsection{The dawn of personal cloud storage privacy}
%Cloud providers like MediaFire, 4shared and the former MegaUpload provide a personal storage platform through the web for file sharing and archiving, be it public or private.
%Such services, known as `cyberlockers' have become popular over the past decade or so, to the point where they can be considered ubiquitous.
%The larger of these websites have in fact become so popular that they are in the lead for most visited sites and are among the most significant global internet bandwidth users.
%Sharing services like these are known to be used as trafficking vehicles for pirated copyrighted media as they can provide free storage in a way that in most cases can be used anonymously, and can even generate profit for the uploader.

%One of such companies was the former MegaUpload: a company which had its assets seized by the United States Department of Justice in early 2012 on claims of illegal file sharing activity, in what is still unfolding as a particularly complex legal case.
%The company has since reinvented itself as MEGA, providing the same services but boasting better privacy and security by using cryptographic methods to mask the stored data.
%Following the (foreseen) legal prosecution, other companies like Ciphercloud and SpiderOak have also brought forth solutions to similar concerns.
%While MEGA and SpiderOak seem to have taken a cue from the cryptography community and chose to be open about their design to their users, Ciphercloud have recently become the center of controversy after they tried to file a DMCA takedown notice against a StackExchange thread in which their cryptography scheme was analyzed and its security/trustworthyness became the subject of speculation~\cite{ciphercloud}.
%Given the lack of provided open-source implementations, it still seems the cryptography argument is a bit of a hand-wave.
%We have decided to summarize some issues regarding these new designs in \autoref{sec:technical_analysis}.


\section{Legal analysis}
\label{sec:legal_analysis}

In this section we will review the relevant legal aspects surrounding cloud computing.
We will focus on the European legal framework (and our local Dutch adaptation) since it best fits our own perspective, but moreover because appears to be the most thorough legislation with regards to legal privacy guarantees.
This perspective is directly contrasted by the American framework, which seems to take a more conservative stance, providing more legal foothold for law enforcement and intelligence agencies to investigate.

\subsection{Legal Code}
The Council of Europe has recognized the right to privacy as a human right from its inception, and as such has included a obligation to uphold this right in its European Convention on Human Rights (ECHR) which was signed by \emph{all} of its member states.
ECHR Article 8, ``Right to respect for private and family life'', gives a broad definition of the right to privacy which has been upheld by the European Court of Human Rights in a broad interpretation.

In the same vein the EU Data Protection Directive 95/46/EC grants EU citizens the right to keep their personal data private, full stop.
\cite{directive199595}
The default principle of the law is that personal data should not be processed \textit{at all}, except when explicit requirements are met.

%in telecommunications networks by forbidding service providers from intruding on their personal information without having received explicit permission in advance.


%Local legislature that applies is the \textit{Wet Bescherming Persoonsgegevens} (WBP)
% TODO

\subsection{What is Covered}
Personal data is again defined very broadly, as:
\begin{quote}
... any information relating to an identified or identifiable natural person ('data subject'); an identifiable person is one who can be identified, directly or indirectly, in particular by reference to an identification number or to one or more factors specific to his physical, physiological, mental, economic, cultural or social identity
\end{quote}

%This means that permission to collect

%This directive is based on seven key principles surrounding citizen privacy.
%They are as follows:
%\begin{itemize}
%\item Data subjects should be given notice of collection;
%\item Data should only be used for the purposes specified;
%\item Data should not be disclosed without the subject's consent;
%\item The data processors should uphold adequate security;
%\item It should be disclosed to data subjects who is processing their information;
%\item Data subjects should be allowed to access and update their data;
%\item It should be possible to hold data collectors accountable to these principles.
%\end{itemize}

This legislature is set to be succeeded by the General Data Protection Regulation, which amends the code to extend its reach beyond the EU, and applies everywhere information about EU citizens is collected.
It also mandates that data breaches must be reported to the Data Protection Authority, and stipulates serious fines for failure to comply.
Note, however, that this regulation is still under review and thus subject to change.

Complementary to the Data Protection Directive is the E-privacy Directive (Directive on Privacy and Electronic Communications), which also protects citizens from excessive data retention, spam e-mail and the use of tracking cookies without explicit consent.
This document spawned the much-debated ``Cookie law'' (Cookiewet) in the Netherlands.

In a cloud computing setting, the main legal problems boil down to two issues: accountability of non-EU companies and multi-tenancy of cloud applications. Essentially, the problems emerge from different users belonging to different jurisdicitions using a system that is possibly in yet another jurisdiction. Try enforcing anything when the user lives in Europe, accessing an Asian server of an American company. Problems aplenty, we should think.

The type of cloud system, i.e., ``the X in XaaS'', also has its part to play in the legal setting of cloud computing.
From IaaS (infrastructure) to SaaS (software), the responsibilities concerning privacy of provider and client change.
In an IaaS setting, the provider can only do so much to provide privacy safeguards.
The responsibilities lie primarily in providing availability of the infrastructure as well as providing hypervisor and physical security.
The IaaS client is responsible towards their respective clients for building secure applications or platforms on top of this infrastructure.

The SaaS provider is ultimately accountable.
That is, a user needs to be sure that the software is adequately secured on infrastructure, platform and software level.
Obviously, in the PaaS setting the responsibilities lie somewhere halfway between IaaS and SaaS. The provider needs to provide a secure platform but it is the client's job to provide the necessary safeguards for any application built on top of this platform.

We like to note that when applying the sort of the solutions we describe in \autoref{sec:pet} we process significantly less personal data. Say, for instance, that we have a situation in which we want to search in a database. Now, if we apply techniques to search using encrypted queries in an encrypted database, we stop processing any personal data that is not linked to the communications protocol (like IP addresses). Such techniques, are in a way a win-win solution. They reduce liability risks for providers and provide privacy for users.

As a side note, the United States Department of Commerce has worked with the EU to develop the Data Protection Directive principles into what they call ``Safe Harbor'' principles which US companies can opt-in to.
This essentially allowed US companies to do business with the EU, which has the more stringent data protection legislation.
Also, the Digital Millennium Copyright Act (DMCA) recognizes the concept of a ``mere conduit'' (of information) as did the European Data Protection Directive. \cite{congress1998digital}
It should be noted that, currently, the protections the EU legislation provides do not extend beyond its borders.
Even after the new legislation comes into effect, the PATRIOT act~\cite{mailman2002uniting} still allows the United States to demand access to any businesses that operate there in the interest of national security.

% In hindsight, doing contract law was probably a bad idea, except for the auditing standards mentioned above..
% \subsection{Contract law}
% SLAs and how undesirable some of their provisions are


% Article 29 WP opinion (draft, nog geen reference)

%\subsection{Case law}
%Lindqvist case

% Legal responsibilities as a function of the type of cloud architecture (see slides for the idea)

%\section{Current State of Affairs: Private Cyberlockers}
%\label{sec:technical_analysis}
%%Security considerations in cloud infrastructure

%%Summary of techniques for security, focussing on Confidentiality and Integrity as we know them from general computing

%%\subsection{Hypervisor security}
%%``Reflections on Trusting Trust'' by Kevin Thompson \cite{thompson1984reflections}

%%Hardware backdoors \cite{sparks2009chipset, duflot2010limits}

%%Reverse engineering requirement
%%\cite{rutkowska2008bluepilling}
%%In this section we shall provide a cursory review of the current state of affairs in technical solutions as implemented, or to be implemented, by some of the cloud storage providers out there.

%%\subsection{Case study: private cyberlocker}
%%\label{sec:cyberlocker}
%%How MEGA/Megaupload tried to cover themselves (and to a lesser extent their users) from the burden of accountability for the data they host
%%
%%Our ideas to keep private data private in cloud storage without sacrificing de-duplication
%%(subject to further experimentation)
%Following the disturbance in the cyberlocker ecosystem following the seizure of MegaUpload there has been growing interest in secure private cyberlocker services.
%This seems like a win-win situation for privacy: the cyberlocker sites have plausible deniability with respect to the content they are hosting, and their users can feel secure about their data privacy.
%We must ask ourselves why there is no true openness from any such providers of note to be found in the literature or when surfing the web. \cite{borgmann2012security}
%We have, however, tried to find out what we can from public sources about two newcomers to the scene.

%%In the market of so-called `cyberlocker' sites most don't use (or boast) any privacy enhancing technologies, and  those that do are not always open about their workings.
%MEGA and SpiderOak are both open about the fact that they make use of a layered approach whereby files are encrypted with strong random passwords, which are then encrypted by a single master password associated with the user.
%Assuming the underlying cipher and random generation algorithms are implemented in a cryptographically secure way such a scheme seems quite secure: neither the files nor their keys ever reach the server in the plain.
%Their approaches diverge when it comes to application delivery: where MEGA opted for in-browser delivery of content over the HTTPS channel SpiderOak chose to draft a native application for its service to better ensure application integrity (as it runs in a separate context).

%The SpiderOak client so far remains a closed-source application, but at least its code and behaviour can be audited and validated using traditional means.
%Compare this to MEGAs due to their choice of the web browser as a code delivery environment, which is much more tamper-prone due to its intended malleability by add-ons.
%An adversary that could manage to infect our browser through a malicious add-on (which is more likely to happen than infecting the host) would be able to intercept and modify our entire interaction with the MEGA service.

%Both of these services offer de-duplication, but SpiderOak makes sure to point out it does not do so across users because they apply \textit{personal encryption} to each file.
%As we understand it, this also describes MEGAs scheme: neither can do secure de-duplication across users without linking users to content, and therefore avoid doing so.

%But if MEGA truly has no idea of what users upload to their service, how should we read the headline ``Kim Dotcom Pulls 3D Printed Gun Plans from MEGA''~\cite{3d_gun}.

%\subsection{Past attacks}
%Past security vulnerabilities (that threaten privacy)
%\cite{meer2009clobbering}

\section{Privacy-Enhancing Technologies}
\label{sec:pet}

Legal solutions as we studied in the previous section do not actually solve our biggest problem. 
They do not aid us in protecting our data, and thus our privacy, from potentially malicious third parties. 
What we need are systems that give guarantees about the privacy of our data even in a setting with a hostile third party. 
The most obvious, and probably even the only, solution is to make sure that even the cloud provider cannot, by any interal means, access the data. 
If the cloud provider cannot do so, we also prevent mass privacy violations by parties using the cloud providers access, whether they be governmental or criminal in nature. 
In this section we shall attempt to describe a few ways in which to accomplish this to some degree for some applications. 
In particular we shall discuss searchable encryption (SE), fully homomorphic encryption (FHE) and functional encryption (FE).
Note that we shall not attempt to describe any given concept with the greatest level of (mathematical) detail, instead we shall focus on supplying the definitions and the intuition required for understanding how we can use these technologies to aid in our endeavour to make clouding computing more friendly to our privacy.

Before we discuss the mentioned technologies it is import to note that the application of cryptography to provide privacy may not be generally feasible in a cloud setting. 
Van Dijk and Juels~\cite{van2010impossibility} formally defined a class hierarchy for cloud applications and went on to prove that for two out of three, even powerful primitives such as fully homomorphic encryption, are not enough to provide privacy. 
They considered three classes of cloud applications, namely

\begin{enumerate}
    \item Private single-client computing, computation on data of a client such that only this client can learn the output;
    \item Private multi-client computing, computation on data of multiple clients such that the output may be selectively learned only by certain clients using some form of access control;
    \item Stateful multi-client computing, similar to private multi-client computing except that the access control policy depends on previous application execution.
\end{enumerate}

Note that this last class actually contains a great many typical cloud applications, e.g., social networks. 
Therefore the result that neither the second nor the third class actually realizes privacy in the general sense is quite important; some form of trusted state or execution is always required in those two classes.
We do feel, however, that even in the face of such a result the study of the techniques in the next few sections is worthwhile and useful because they can provide privacy in specific applications and use cases.
In a sense, the result is also quite reassuring, i.e., as long as data need not be shared among clients it is indeed very possible to get privacy using more general methods like FHE.

% Literature suggests a few alternatives to placing trust in a single third party, such as:
% \begin{itemize}
% \item \textit{server-aided cryptography}, where a third party server does some `heavy lifting' for its clients without having access to their secrets;
% \item the as of yet underdeveloped notion of \textit{information-centric security}, where data is self-describing and self-defending, regardless of the context; \cite{chow2009controlling}
% \item establishing trust by \textit{consensus} among a number of peers;
% \item the still-developing field of \textit{Fully Homomorphic Encryption}, which would allow computations to be applied to data that \textit{remains under encryption}.
% \end{itemize}

% Certain recent technologies provide ways to interface with cloud services with some measure of privacy.
% Two of these privacy-enhancing technologies are \emph{search under encryption} and \emph{reusable garbled secrets through functional encryption}.
% Both come from the realm of cryptography and it should be noted that it is likely that encryption is never enough to provide privacy in the general case of cloud applications \cite{van2010impossibility}.
% However, we feel that these two technologies can help in protecting the privacy of the user of cloud services.

\subsection{Searchable Encryption}

One application of particular interest in a cloud computing setting is that of searching through data.
It is not hard to imagine that, in a world where we store more and more data in the cloud, we would like good and secure ways to search through said data.
However, we may not trust the cloud provider with knowing what we are searching for nor what sort of data is stored.
Enter searchable encryption, a scheme where both the stored data and the queries are kept secret.
In this section, we shall first describe a fairly simple system of searchable encryption as devised by Boneh~\cite{boneh2004public} called Public-Key Encryption with Keyword Search (PEKS).

Boneh describes the system in specific, but easily generalizable, setting, i.e., the routing of encrypted e-mail messages depending on the occurrence of certain keywords in this message. 
The goal is to test whether a keyword occurs in a message without learning any other information about the message.
Note that such a goal can conceivably be achieved using the functional encryption scheme that we shall later discuss but we do not necessarily need the full power of such a scheme for this relatively simple goal. This scenario, when storing the encrypted mail on an IMAP server, is analogous to a cloud provider storing such messages.

The scheme is, conceptually at least, not very complicated. Let us say $B$ wants to send $A$ an encrypted message using the PEKS scheme. The message would look like this:
\[
    \left[ E_{A_{pub}}(m), \op{PEKS}(A_{pub}, W_1), \dots, \op{PEKS}(A_{pub}, W_k) \right]
\]
where $A_{pub}$ is $A$'s public key, $m$ is the message $E_k(m)$ is the encryption of $m$ under $k$, PEKS is the algorithm that provides searchable encryption and $W_1, \dots, W_k$ are the keywords associated with $m$.

For the scheme to work we need the following four algorithms:
\begin{itemize}
    \item $\op{KeyGen}(s)$: Generates public/private keypair $(A_{pub}, A_{priv})$ given security parameter $s$;
    \item $\op{PEKS}(A_{pub},W)$: Given the public key and a word $W$, provide a searchable encryption of $W$;
    \item $\op{Trapdoor}(A_{priv},W)$: Produce a trapdoor for $W$ given the private key and a word $W$;
    \item $\op{Test}(A_{pub},S,T_W)$: Given the public key, a searchable encryption $S = \op{PEKS}(A_{pub}, W')$ and the trapdoor $T = \op{Trapdoor}(A_{priv}, W)$, test whether $W = W'$ and output 'yes' or 'no' accordingly.
\end{itemize}

A query would then consist of sending a trapdoor of a message to the server and this server could then, given the existence of the Test algorithm, return all messages containing this keyword.
Boneh notes that this scheme, as is, is semantically secure against an adaptive chosen keyword attack but not against a chosen ciphertext attack.
It can, however, be adapted to provide such a guarantee.

It turns out that we can construct these four algorithms using any trapdoor permutation (other constructions are given, but we shall forego those). 
We need two guarantees: a polynomially bounded number of keywords and an encryption system that is source-indistinguishable, i.e., it is computationally hard to determine with which key a given ciphertext was encrypted with. 
In order to now construct the PEKS system we need to define the four algorithms in terms suitable to this particular construction, i.e., with trapdoor permutations and source-indistinguishability. 
The algorithm can be constructed as follows, where $\Sigma$ is the family of keywords, polynomial in size:
\begin{itemize}
    \item $\op{KeyGen}$: Generate a public/private keypair $PK_W/Priv_W$ for each $W \in \Sigma$. The resulting public key $A_{pub}$ is $A_{pub} = \{ PK_W | W \in Sigma \}$;
    \item $\op{PEKS}(A_{pub},W)$: Output $\op{PEKS}(A_{pub}, W) = (M, E_{PK_W}(M))$ for a randomly picked $M = {0,1}^s$;
    \item $\op{Trapdoor}(A_{priv},W)$: Simply output $T_W = Priv_W$;
    \item $\op{Test}(A_{pub},S,T_W)$: Test whether the decryption $D_{T_W}(S) = 0^s$ and output 'yes' or 'no' accordingly.
\end{itemize}

While this construction is very simple and generic in its application, we can do much better in terms of efficiency. 
The fact that (seemingly) we require a very, very large public key is a detriment to the applicability of this scheme.
However, if we use a more specific construction (or a more optimized version of the above) we can avoid this problem.
In fact, in the very same paper Boneh explains a construction based on hash functions and bilinear maps that is much more efficient.

Concerning searchable encryption, we can definitely see applications for such a system. 
Given that it should be more efficient than, say, FHE we can probably use such a system for doing keyword searches in cloud-stored documents. 
Note that this is a particular version of searchable encryption, for other situations we may want more specialized schemes, especially if we want to do complicated queries.
Also, such a scheme as this exposes the access pattern of the user requesting the search, i.e., the provider may not learn the content of the messages but it can learn which messages are frequently accessed and so forth.
A solution to this problem is given by Boneh in~\cite{boneh2007public}.
In fact, Li~\cite{li2010fuzzy} argues that the fact that this scheme only provides exact-keyword search makes it unsuitable for cloud computing. 
They go on to propose a system for doing fuzzy searches. This is, although quite a bit more fancy, necessarily more complex as well.

% Conceptually, PEKS is very simple:
% Say people send Alice messages that are stored in some database.
% These messages are constructed as follows:
% given an encrypted message $msg$ containing words $w \in msg$, append to the encryption of $msg$ the PEKS encryptions of $w$ under the public key of the Alice.
% The PEKS encryption works by having a separate keypair for each word $w$, the total of all of the public keys form the final public key of Alice, and the total of the private keys  from the final private key in the same manner. The encryption then returns a tuple containing some random value $M$ and the encryption of $M$ under the private key corresponding to $w$.
% Finally, if Alice wants to query the message database, she constructs a trapdoor which is simply the private key corresponding with the word $w$ the wants to query for.
% An algorithm that tests for the existence of the keyword gets such a tuple and a trapdoor and attempts to decrypt the second part of the tuple using the trapdoor until the decryption matches the first element of the tuple.
% If this happens for a word belonging to a message, the message contains the word. 
% In this, slightly simplified, version of the scheme, we cannot guarantee chosen-ciphertext security although modified versions may actually provide such a guarantee.
% Also, performance is quite bad due to the massive amounts of public key operations (and even generation) going on in this scheme.

% Note that Boneh would go on to provide some better solutions in \cite{boneh2007public}, but we shall not discuss those here.
% Also, research has been done \cite{li2010fuzzy} on providing fuzzy keyword searching, i.e., when searching for ``foo'' we actually want to search for all keywords corresponding to ``*f*o*o*'', where * is the wildcard character.


% Only store encrypted data, Let clients perform crypto so it can be validated externally
% \cite{kamara2010cryptographic}

% Homomorphic encryption,
% Searching in encrypted data \cite{harrower2009searching, li2010fuzzy}

\subsection{Fully Homomorphic Encryption}

We feel comfortable saying that fully homomorphic encryption (FHE) is one of the more interesting and promising advances in cryptography of the last decade. 
It allows for performing complex dynamically-chosen computations on data while said data remains encrypted. 
In the context of cloud computing, FHE is especially interesting.
Take, for instance, one of the services a cloud provider might provide, namely the outsourcing of computational power.
Using the ability to compute arbitrary functions over encrypted data allows one to use such external computation power without exposing what is being computed (and which data is used).
It is important to note that at the time of writing efficient ways to implement an FHE scheme do not yet exist in any practical sense.
However, progress is being made in this area.

The first properly working construction of FHE is due to Gentry~\cite{gentry2009fully} in 2009, which also construed a blueprint of sorts for building a FHE system.
A full, precise explanation of FHE as per Gentry's construction, or any of the later ones is truly outside the scope of this particular paper. 
Instead, we refer the reader to~\cite{vaikuntanathan2011computing} for a more complete, but not to in-depth, overview of FHE and to~\cite{brakerski2012leveled} for a fairly recent construction of FHE that is not directly based on Gentry's original blueprint but on the (Ring) Learning with Errors problem. 
What we shall do is to provide a more general overview of what FHE entails and what its properties generally are. 
For the sake of consistency with the next section we shall use the definitions and notation from~\cite{goldwasser2013reusable}, which are in turn adapted from~\cite{vaikuntanathan2011computing}.

We can define FHE scheme as a quadruple of polynomial time algorithms $(\op{FHE.KeyGen}, \op{FHE.Enc}, \op{FHE.Dec}, \op{FHE.Eval})$:

\begin{enumerate}
    \item $\op{FHE.KeyGen}(1^k)$: A probabilistic algorithm that given security parameter $k$, outputs public/private keypair $pk/sk$;
    \item $\op{FHE.Enc}(pk, x \in \{0,1\}$: A probabilistic algorithm that given the public key and an input bit outputs ciphertext $\psi$;
    \item $\op{FHE.Dec}(sk, \psi)$: A deterministic algorithm that given the secret key and a ciphertext outputs the message $x^* \in \{0,1\}$;
    \item $\op{FHE.Eval}(pk, C, \psi_1, \psi_2, \dots, \psi_n)$: A deterministic algorithm that given the public key, a circuit taking $n$ bits as input and $n$ ciphertexts, outputs a ciphertext $\psi_C$.
\end{enumerate}

A construction of such a scheme is \emph{homomorphic} if given $\psi = \op{FHE.Eval}(pk, C, \psi_1, \dots, \psi_n)$ the chance that $\op{FHE.Dec}(sk, \psi) \neq C(\psi_1, \dots, \psi_n)$. 
It is \emph{compact} if the output size of $\op{FHE.Eval}$ is at most polynomial in the security parameter $k$.
The construction is fully homomorphic if for all arithmetic circuits $C$ over $GF(2)$ the scheme is both compact and homomorphic.

The construction in the next chapter will use a \emph{leveled} FHE scheme. 
Such a scheme is defined as an FHE scheme where $\op{FHE.KeyGen}$ takes a second parameters $1^d$ and the scheme is fully homomorphic for all $d$-depth arithmetic circuits over $GF(2)$. 
We suppose, as per~\cite{vaikuntanathan2011computing}, that other types of circuits than arithmetic ones are possible, but for the sake of ease we shall not consider those.

\subsection{Reusable Garbled Circuits}

Goldwasser \cite{goldwasser2013reusable} recently provided the means to reuse so-called garbled circuits by means of a functional encryption scheme using \emph{succinct} functions.
This allows the computation of succinct functions on encrypted data without learning anything but the result of the function.
To reuse Goldwasser's example, this allows us to, say, compute a spam-detection function on encrypted mail that learns nothing about the contents of said mail except whether it was classified as spam.
We shall not go into the details of the security properties of this system but we shall attempt to indicate how they work.

Essentially, a garbled circuit allows computation of a given function $f(x)$ without leaking information about $f$ or $x$.
The only information learned is the output, $f(x)$.
More precisely, we have a circuit $C$ that computes the respective function given input $x$.
We garble the circuit by encoding it using some one-way function, this outputs the garbled circuit $C'$ and a secret key $sk$.
The input $x$ is also encoded in order to fit the newly generated circuit.
These circuits basically need to provide two things: the privacy of $x$ and the privacy of $C$ (input privacy and circuit privacy, respectively).
Historically, such a garbled circuit was for one-time use only, new input required new encodings.
What Goldwasser did is to provide a way to, with only one key and thus one encoding, apply the circuit to a polynomial number of inputs.

As stated, in order to reuse such circuits we need a function encryption (FE) scheme.
In such a scheme, we have a master public key $mpk$ that anyone can encrypt data with.
Furthermore, the data owner can issue keys for functions that given a key $sk_f$ and ciphertext $c$ corresponding to input $x$ can compute $f(x)$ on $c$ using $sk_f$.
In this case we rely on homomorphic encryption to make sure that we can actually compute on encrypted data in a semantically secure way.

Now that the components are laid out, we shall go on to describe, very globally, the workings of Goldwasser's reusable garbled circuits.
As mentioned, we use fully homomorphic encryption (FHE) in order to compute on encrypted data.
The security of FHE guarantees no information leaks on the input $x$, therefore providing the input privacy that we need.
We now use a functional encryption scheme using FHE to compute functions $f$ on given input.
Still lacking is the ability to provide circuit privacy.
In Goldwasser's scheme, this is accomplished by garbling circuit $C$ using a semantically secure encryption scheme in combination with said functional encryption scheme.
This yields the garbled circuit $U$ and a secret key for $U$ such that given $sk$ and $x$, U will decrypt $C$ and yields $C(x)$.
In this scheme, we can reuse the circuit for a polynomial amount of inputs.

For a precise definition of the functional encryption scheme used and the reusable garbled circuit that follows we refer the reader to Goldwasser's excellent paper; this section was only intended as a global overview.

Given such a scheme as this, how does it apply to our particular use case?
In a cloud setting we can think of several services being given keys for functions corresponding to the service they provide.
All these services could operate on any data encrypted with the master public key, regardless of origin.
One such service might provide search functionality, as described in the previous section;
another might provide some consistency check of the underlying plaintext data;
yet another may generate statistics over some collection of encrypted data.

\section{Conclusion}
\label{sec:conclusion}

Cloud computing is still becoming increasingly more popular and thus making sure we ``do it right'' becomes more important as well.
In this paper we have attempted to provide an overview of the problems, both legal and technical, surrounding privacy and cloud computing as well as an overview of the current situation with modern cloud providers.
Furthermore, we have described two privacy-enhancing technologies, searchable encryption and reusable garbled circuits.
The latter being a very generic approach to applying functions to encrypted data, the former being a solution to a specific problem, i.e., searching encrypted data.
At the time of writing this paper, both solutions are likely infeasible to implement on any serious scale due to the performance issues associated with them.
However, we can hope that Moore's law in combination with bleeding-edge research can alleviate this pain some time in the future.

On a more personal note, we feel that the legal framework in Europe, especially considering the new and improved data protection regulation, is among the best in the world. We hope that sanity prevails in the face of over 2000 amendments to said regulation.

Concluding, we like to emphasize through repetition that doing cloud computing privacy right is very, very important lest we succumb to the generally upheld belief that privacy is dead. \textbf{It does not have to be}.

%\section{References}

\bibliography{Cloud_Privacy}{}
\bibliographystyle{unsrt}

\end{document}

% vim:tw=0:wrap

