\documentclass[12pt]{article}
\usepackage{enumitem}
\usepackage{listings}
\usepackage{color}
\usepackage{tabularx}

\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{sidecap}
\usepackage{epstopdf}

%\def\bibfont{\scriptsize}

\usepackage{natbib}
\setlength{\bibsep}{0.0pt}

\begin{document}
\title{Privacy in Cloud Computing}

\author{Erik Boss \and Aram Verstegen}
%\institute{Radboud Universiteit Nijmegen}
\date{\today}
\maketitle

\abstract{We summarize our concerns for observed and potential privacy risks associated with cloud computing in a broad sense, subsequently review the legal aspects concerning data protection from a European perspective, followed by a summary of two related and applicable privacy-enhancing technologies uncovered in our literature study, and conclude by reflecting on the state of affairs.}
% TODO rewrite...

\section{Introduction}
In recent years there has been a lot of positive buzz surrounding the idea of \textit{cloud computing}: a systems design trend that allows applications to run as ubiquitous services by providing abstractions to the lower layers of application architecture.
These layers can be distinguished as \textit{Software}, \textit{Platform} and \textit{Infrastructure} and each of these has a different target audience which can buy these facilities ``as a service'', i.e., Software/Platform/Infrastructure as a Service (SaaS, PaaS, IaaS). 
Such abstractions bring benefits like implicit redundancy, centralized security measures and, most importantly, reduces capital and operational expenses for customers by the increased efficiency at which each layer can be managed.

That being said, there is also a note of concern with things like centralized information management, giving up physical segregation for logical segregation, near-infinite storage capacity, cheap, ubiquitous computing power and the legal issues surrounding information processing systems whose infrastructure scale transcends national borders.

In cloud computing it's apparent that there is a very strong connection between security and privacy.
If any central component of cloud infrastructure were to be compromised it could almost certainly be used to disclose very privacy-sensitive information, given the scale of cloud infrastructure providers and what kind of private information is (or can be) recorded using applications running ``in the cloud''.
In fact, there is no proof or technically feasible way to prove that such a compromise has not occurred already.

Some of these issues culminate in the recently much-publicised case of mass surveillance by the United States National Security Agency and its overseas partners.
As more facts on this case are being made public we are better equipped to make informed choices in how we interact with the manifestations of this technology trend.
We no longer need speculation on a worst-case estimate alone to build our adversary model, we now have concrete evidence that our data privacy and computational privacy are at risk.

In this article we will go over some of the potential and actual privacy-related problems that we have encountered as part of our study on the technical and legal domains of cloud computing. Starting off, in \autoref{sec:problems_in_cloud_computing} we give a fairly broad overview of the privacy-related issues encountered within the cloud computing era.
This will lead into an analysis of the current legal situation regarding cloud computing from a local perspective in \autoref{sec:legal_analysis}. In \autoref{sec:pet} we will go over the technical details and specifically describe some of the solutions to privacy-related problems in cloud computing by means of Privacy Enhancing Techologies (PETs). Finally we reflect on our findings and give concluding remarks in \autoref{sec:conclusion}.

\section{Privacy problems in cloud computing}
\label{sec:problems_in_cloud_computing}
%General concerns with cloud security: centralisation, single point of failure, corporate espionage, subpoenas to the provider, impact of security compromises
%In the multi-layered design of cloud-based infrastructure our privacy concerns are mostly contained within individual layers.

While centralization of infrastructure should generally imply better basic physical and network security, it may lead to greater fragility of the networked ecosystem as a whole, whereby attacks have greater impact than in a strictly distributed environment.
Consider how acts of observation, manipulation or destruction would be more effective when carried out against the central node in a star-shaped network rather than anywhere in a well-connected network.
There exists more redundancy in the more connected network, which helps make the infrastructure more robust against any such disruptions.
%For a trustworthy internet we want to have more connection points into the network than the adversary can conceivably take over.
%Some systems may appear to be more (logically) distributed than they actually (physically) are. 

\subsection{Third Parties}
It seems to us the main privacy problem with the cloud paradigm is the trend all but forces users to relinquish control of previously self-hosted information to fewer and fewer third parties.
%The infrastructure layer is at the bottom of the application stack, with platform and service layers respectively building upon that foundation.
The competitive advantage achieved with scale allows a few key players to lead the Cloud market with an overwhelming majority.
The IaaS market is dominated by Amazon who have a 35\% market share, their closest competitor is IBM with only a 5\% share.
PaaS seems to be a more competitive field, with the top three players Salesforce, Amazon and Microsoft each taking roughly 15\% of the market.
% TODO Cite http://www.telegeography.com/products/commsupdate/articles/2013/03/11/amazons-cloud-iaas-and-paas-investments-pay-off/
SaaS is the most diversified layer in the cloud paradigm, the problems we see here are not in market share but in sheer scale.
Large U.S.-based companies like Facebook, Twitter and Google openly construct behavioral profiles of their millions of `users' on behalf of their `clients' - and are severely treading on user privacy in the process.
Google has announced their own `Compute Engine' IaaS service only last year, but we feel they have the capacity to oust Amazon from the leading position in the years to come.

\subsection{Cause for Concern}
Having only a few companies in physical possession of so much personal data is cause for concern in light of the aforementioned fragility that large, centralized information systems are susceptible to with regards to observation, manipulation or destruction of data.
Of course these companies do not have a monolithic infrastructure behind their facade; but insiders, legally mandated government agents and clandestine intruders may (hypothetically) reach far into their systems and attain full access to any information stored there.

In the light of recent revelations related to U.S. surveillance programmes, this appears to be much less hypothetical than we initially assumed.
The expectation of privacy when dealing with such companies not only lacks a factual foundation to begin with, but now even the notional expectation of privacy has been severely diminished.
At the risk of being cynical: the upshot here is that the public's perception of cloud-related privacy matters is more in line with reality now that they are better informed.


\subsection{Computational Privacy?}
%A first step in the right direction is to provide \textit{end-to-end encryption} for data in transit.
We should discern the difference between privacy of \textit{data} and privacy in \textit{computation}.
To illustrate: a data file with private information can be kept secret while hosted in `hostile territory' by means of conventional encryption schemes - provided the general cryptographic caveats like choice of cipher and operation mode, key generation/management/distribution et cetera are properly addressed - but the required encryption operations and the party that applies them must also operate \textit{consistently} for this scheme to be secure.
%The main concern in related research is surrounding data privacy, but we find computational privacy to be of equal or greater concern.
%Remotely hosted applications come with the inherent problem that their behaviour can be more difficult to analyse in order asses their security and privacy safeguards.

Data privacy is something we as computer scientists understand well in terms of secrecy, but computational privacy has actually been dauntingly hard to make sense of to us - we see backdoors \emph{all the way down}.
Whereas with personal computing the integrity of the system can be verified down to the hardware level - systems can be tested to confirm to the specifications using \textit{reverse engineering} methods on hardware and software and this can be validated externally, the cloud environment only allows the most cursory glance at the inner workings.
%offers only a superficial analysis until we hit the Virtual Machine barrier; the VM actually functions as a `black box'.

The problem is exacerbated by the fact that virtualization technologies abstract systems from the hardware layer, and require systems built upon them to similarly trust this technology during computation.
And again there is centralization in these technologies, leading to concerns about (virtually) universal backdoors in all systems built upon a handful of such technologies.

\subsection{Formalisms and Philosophy}
%This means we require trust in providers' ability to adequately handle privacy-sensitive information.
The strength of encryption schemes can be proven in relation to the hardness of a mathematical problem, but we have no analogous formalism at our disposal with which to gauge consistency in who or what performs these algorithms - let alone enforcing \textit{provable} integrity through formal methods in this black box environment.

%Provided we can achieve perfect data privacy using PETs

%TODO Cite http://cryptome.org/2013/08/callas-snowden.htm
John Callas quite recently opined on this matter and lucidly identified it to be a deeply philosophical problem - G\"odel's second incompleteness theorem, which states a system cannot be proven consistent from within that very system.
His response to these problems is then to concede to a system that is simply `good enough'.
We should therefore construct systems that conform to our specifications and employ an \textit{external} verifier system - this is the best we can do and is also the basic premise of the proposed PETs.


%We want to cover either of these two cases:

% Dit heeft eigenlijk niks met cloud privacy te maken... NSLs mogen alleen transactionele data opvragen
%\subsection{Problem case summary: Doe vs Ashcroft}
%In the United States there exists an investigative tool
%An investigative tool for intelligence agencies like the FBI known to be in use since 1978 is the National Security Letter (NSL): a demand letter for transactional records, accompanied by an indefinite gag order forbidding disclosure of the demand.
%Summary of the story of an ISP that got a NSL - and what an NSL actually demands
%\cite{garlinger2009privacy, gorham2008national}

%\subsection{Problem case summary: Cyberlocker raids}
%How cloud providers are being held accountable for the content they host

%\subsection{The dawn of personal cloud storage privacy}
%Cloud providers like MediaFire, 4shared and the former MegaUpload provide a personal storage platform through the web for file sharing and archiving, be it public or private.
%Such services, known as `cyberlockers' have become popular over the past decade or so, to the point where they can be considered ubiquitous.
%The larger of these websites have in fact become so popular that they are in the lead for most visited sites and are among the most significant global internet bandwidth users.
%Sharing services like these are known to be used as trafficking vehicles for pirated copyrighted media as they can provide free storage in a way that in most cases can be used anonymously, and can even generate profit for the uploader.

%One of such companies was the former MegaUpload: a company which had its assets seized by the United States Department of Justice in early 2012 on claims of illegal file sharing activity, in what is still unfolding as a particularly complex legal case.
%The company has since reinvented itself as MEGA, providing the same services but boasting better privacy and security by using cryptographic methods to mask the stored data.
%Following the (foreseen) legal prosecution, other companies like Ciphercloud and SpiderOak have also brought forth solutions to similar concerns.
%While MEGA and SpiderOak seem to have taken a cue from the cryptography community and chose to be open about their design to their users, Ciphercloud have recently become the center of controversy after they tried to file a DMCA takedown notice against a StackExchange thread in which their cryptography scheme was analyzed and its security/trustworthyness became the subject of speculation~\cite{ciphercloud}.
%Given the lack of provided open-source implementations, it still seems the cryptography argument is a bit of a hand-wave.
%We have decided to summarize some issues regarding these new designs in \autoref{sec:technical_analysis}.


\section{Legal analysis}
\label{sec:legal_analysis}

In this section we will review the relevant legal aspects surrounding cloud computing.
We will focus on the European legal framework (and our local Dutch adaptation) since it best fits our own perspective, but moreover because appears to be the most thorough legislation with regards to legal privacy guarantees.
This perspective is directly contrasted by the American framework, which promotes self-regulation and seems to take a more conservative stance toward privacy by providing more legal foothold for law enforcement and intelligence agencies to investigate.

In a cloud computing setting, the main legal problems boil down to two issues: accountability of non-EU companies and multi-tenancy of cloud applications.
Essentially, the problems emerge from different users belonging to different jurisdictions using a system that is possibly in yet another jurisdiction.
%Imagine the user lives in Europe, accesses a server of an American company, located in Africa, perhaps through a VPN located in Asia.
%Is the European user fully protected by European privacy laws or is he at the behest of the American laisez-faire system?
%What about American

\subsection{European Law}
The Council of Europe has recognized the right to privacy as a human right from its inception, and as such has included an obligation on member states to uphold this right in its European Convention on Human Rights (ECHR) which was signed by \emph{all} of its member states.
ECHR Article 8, ``Right to respect for private and family life'', gives a broad definition of the right to privacy which has been upheld by the European Court of Human Rights in a broad interpretation.

In the same vein the EU Data Protection Directive 95/46/EC not only forbids privacy violations but in fact bring positive obligations on member states to uphold the right to privacy. \cite{directive199595}
The default principle of the law is that personal data (that is, any data relating to a natural person) should not be collected or processed \textit{at all}, except when explicit requirements are met.
In principle, personal data may only be collected for the explicit purposes that the subjects consent to.
The collected data must be kept up-to-date, remain accurate, be available to view and correct for the subject, and only be stored as long as it is actually needed.
Processing of collected data \emph{must} have a legitimate purpose; such as to uphold a contract, comply with legal obligations or if this processing is in the express interest of the data subject.

Furthermore the data processors must take measures to safeguard the data against leaking, tampering or data loss, and can be held accountable by the local supervisory authority (such as the Dutch College Bescherming Persoonsgegevens, CBP).
There even exists a special category for \textit{sensitive} personal data (to wit: ``racial or ethnic origin, political opinions, religious or philosophical beliefs, trade-union membership, and [...] data concerning health or sex life'') whose processing shall be prohibited by member states.

So we see there is a strong legal basis to uphold privacy in EU member states.
The definition of private data is broad, the directive states clearly that the norm is privacy by default and the articles appear to cover the ideal of data privacy in every conceivable form - only then are additional exemptions added to this core principle.

A key provision in the directive is that personal data may not be transferred to `third countries', which do not have compatible legislature that uphold the same standard of privacy.
This feature is problematic in transnational business relationships between companies in member states and those in such third countries.
This is of course directly applicable to e-commerce in general, and the cloud computing paradigm particular.

%The type of cloud system, i.e., ``the X in XaaS'', also has its part to play in the legal setting of cloud computing.
From infrastructure to software, the responsibilities concerning privacy of provider and client change.
In an IaaS setting, the provider can (and is legally obligated to) only do so much to provide basic security safeguards.
These responsibilities lie primarily in providing availability of the infrastructure as well as providing hypervisor and physical security, although IaaS providers do not consider security features a competitive advantage.
The IaaS provider's client who becomes a data controller is the one responsible towards their respective clients for building secure applications or platforms on top of this infrastructure under European law.

The data controller provider is ultimately accountable.
%That is, a user needs to be sure that the software is adequately secured on infrastructure, platform and software level.
In the PaaS setting the responsibilities lie somewhere halfway between IaaS and SaaS - the provider needs to provide a secure platform but it is the client's job to provide the necessary safeguards for any application built on top of this platform.

\subsubsection{Working party}
The Article 29 Working Party is an advisory body composed of members of the local supervisory authorities, and have published their (draft) opinion on Cloud Computing in which they argue that clients of cloud computing providers themselves become data controllers, and cannot simply delegate this responsibility to the provider from which they receive their services.
Therefore they recommend that their clients (data controllers) should select a provider which can guarantee compliance with the data protection legislation.
They also recommend cloud customers to do an extensive risk analysis before they commit to a cloud provider which exposes them to more (legal or technical) risks than they are prepared for.

IaaS market leader Amazon has committed to this idea by allowing its customers to `lock' their cloud storage systems to operate only within European borders and thereby safeguard the data under European law.
Microsoft has expressed they are unable to provide any guarantees for this, and opine that any other company could not do so either.
The large American communication companies we are concerned about operate as U.S. companies and are not prepared to keep data locked to our region. Therefore our European rights are not transitive to their systems under current legislation.

\subsubsection{Privacy Online}
Complementary to the Data Protection Directive is the E-privacy Directive (Directive on Privacy and Electronic Communications), which does not override but augments the Data Protection Directive, by additionally obliging member states to protect the privacy of both natural and legal persons in electronic communications.
The main obligation to providers is to provide adequate security and to inform users of security breaches, but it also covers things like excessive data retention, spam e-mail and the use of tracking cookies without explicit consent.
This last provision has spawned controversy as it is deemed to be unenforceable in practice.
Some of their most vocal critics are a group of developers who have created an open source solution to implement a system to use cookies that is in accordance with the directive.
Since the interpretation of the law has changed over time, their software has become largely irrelevant and prompted them to start the campaign \url{nocookielaw.com}.
%This document spawned the much-debated ``Cookie law'' (Cookiewet) in the Netherlands.


%\subsection{United States of America Law}
\subsection{Safe Harbor in the United States of America}
The United States Department of Commerce has worked with the EU to adapt the Data Protection Directive principles into what is called the ``Safe Harbor'' principles which US companies can opt-in to.
This essentially allowed US companies to do business with the EU, which has the more stringent data protection legislation.
This is merely a commercial incentive, not law.
Companies providing safe harbor facilities are expected to be self-regulating in this regard.

\subsection{Risks of Warrantless Wiretapping}
For all the good it does, the Data Protection Directive also provides an exemption from some of the main articles: allowing for member states to implement legislation which restricts the scope of several key obligations put upon them by the directive to safeguard national security and similar aspects of national concern.
% TODO cite
The directive allows for some key principles (relating to data quality and transparency) to be bypassed in such cases.
As such it enables, for instance, the EU Data Retention Directive (2006/24/EC) to be implemented.
This provision \textit{could} allow for member state's participation in blanket surveillance programmes as recently uncovered in the United States.

The 2001 ``Uniting and Strengthening America by Providing Appropriate Tools Required to Intercept and Obstruct Terrorism'' (USA PATRIOT) act is the United States legislation presented to combat terrorist threats, expanding the definition to include domestic terrorism and greatly broadening the legal requirements for intelligence gathering in this context.~\cite{mailman2002uniting} 
It allows United States government agencies to demand access to records of any businesses that operate on US soil in the interest of national security.

The PATRIOT act has also greatly expanded the applicability of the \textit{National Security Letter}, which behave like a subpoena (but have less judicial oversight) for transactional records and data pertaining to natural persons in the interest of national security.
These letters come under a gag order which means the recipient is not allowed to inform anybody of the inquiry.

The ``Foreign Intelligence Surveillance Act'' (FISA, 1978) gives provisions for electronic surveillance of foreign powers and their agents, not excluding domestic surveillance.
FISA warrants are governed by a highly secretive court. Only the number of issued and denied warrants are made public.
The available records show that of the over 30.000 warrants applied for up to 2012, only 11 warrants have ever been denied.
This is because in stead of relying on probable cause, the applicant (the U.S. government) need only demonstrate that the subject of the warrant is a foreign power or an agent thereof.

%This law has recently (2006) been revised by the ``Terrorist Surveillance Act'' to provide retroactive amnesty for warrantless surveillance under presidential authority, provides the FISA court the authority to authorise and oversee new electronic surveillance programs and enables the president to authorize the instigation of such programs in telephone or e-mail communications.

%In 2007 the law was again extended by the ``Protect America Act'' of 2007, which allows the U.S. government to perform `acquisition' of communications where any of the parties is outside of U.S. territory \textit{without a warrant} beforehand for a period of up to 48 hours.
%This act lets the government legally certify their own surveillance programs, and establishes procedures to direct and/or compel providers to provide assistance in these acquisitions.

%In 2008 the next amendment, ``FISA Amendment Act'' was passed and in 2012 it was extended for another 5 years.
%Herein \textit{resident} U.S. citizens are more strongly protected, the telecommunication companies are granted immunity for their cooperation, warrantless detailed descriptions of 
Over the course of 2006 to 2012 this law has been repeatedly amended to: relieve restrictions on surveillance of overseas entities even if they are U.S. citizens, to generally provide greater legal surveillance and/or `acquisition' \footnote{
Actually it seems some legal acrobatics are employed; here `acquisition' means something different from surveillance, as it relates to communications with at least one party outside their national borders.
}
capability, extend surveillance to more types of electronic communications, provide procedures to direct and/or compel providers to provide assistance, granting said providers immunity from lawsuits, to provide the government retroactive immunity for (emergency) warrantless surveillance, extend the period and ease the procedure with which to make the aforementioned warrantless wiretapping legal, and allows the government to legally certify its own surveillance programs.
We're not sure if that is everything related to FISA, but it should give an idea of the reach of this shady branch of government.

Earlier this year an anonymous source, allegedly from within the dutch intelligence service AIVD, was interviewed by the newspaper Telegraaf on the subject of the NSA's blanket surveillance. He confided in them the fact that 1) there are more such programs still unpublicised, 2) the gathered information is accessible to Dutch agents as part of their international cooperation, 3) information inside companies that are unwilling to cooperate can be subversively attained by `activating' embedded agents within these companies, 4) the full rap sheet of any target of surveillance can be made available to the agent via e-mail within the course of several minutes.

Our initial concern for the strength our European laws give was already heightened when we noted the provisions that let member states loosen some of the obligations in light of national security matters.
We still have faith in judicial oversight on this side of the Atlantic ocean, most such intrusive AIVD surveillance tasks require a public prosecutor or magistrate to be held accountable.
From this new point of view it seems like the all the required oversight can be circumvented entirely if the agents simply ask their helpful overseas colleagues.
This thread of the story \textit{demands} further investigation.
% TODO cite http://www.telegraaf.nl/digitaal/21638965/__Ook_AIVD_bespiedt_online__.html

%These requirements entail:
%\begin{itemize}
%\item Data processing must be \textit{transparent}: the consent must be explicitly given
%\end{itemize}

%in telecommunications networks by forbidding service providers from intruding on their personal information without having received explicit permission in advance.


%Local legislature that applies is the \textit{Wet Bescherming Persoonsgegevens} (WBP)
% TODO
%This means that permission to collect

%This directive is based on seven key principles surrounding citizen privacy.
%They are as follows:
%\begin{itemize}
%\item Data subjects should be given notice of collection;
%\item Data should only be used for the purposes specified;
%\item Data should not be disclosed without the subject's consent;
%\item The data processors should uphold adequate security;
%\item It should be disclosed to data subjects who is processing their information;
%\item Data subjects should be allowed to access and update their data;
%\item It should be possible to hold data collectors accountable to these principles.
%\end{itemize}

\subsection{Looking ahead}

%Also, the Digital Millennium Copyright Act (DMCA) recognizes the concept of a ``mere conduit'' (of information) as did the European Data Protection Directive. \cite{congress1998digital}
It should be noted that, currently, the protections the EU legislation provides do not extend beyond its borders.
This Data Protection Directive is set to be succeeded by the General Data Protection Regulation, which amends the code to extend its reach beyond the EU, and applies everywhere information about EU citizens is collected.
It also mandates that data breaches must be reported to the Data Protection Authority, and stipulates serious fines for failure to comply.
Note, however, that this regulation is still under review and thus subject to change.

%Even after the new legislation comes into effect, the PATRIOT act~\cite{mailman2002uniting} still allows the United States to demand access to any businesses that operate there in the interest of national security.


% In hindsight, doing contract law was probably a bad idea, except for the auditing standards mentioned above..
% \subsection{Contract law}
% SLAs and how undesirable some of their provisions are


% Article 29 WP opinion (draft, nog geen reference)

%\subsection{Case law}
%Lindqvist case

% Legal responsibilities as a function of the type of cloud architecture (see slides for the idea)

%\section{Current State of Affairs: Private Cyberlockers}
%\label{sec:technical_analysis}
%%Security considerations in cloud infrastructure

%%Summary of techniques for security, focussing on Confidentiality and Integrity as we know them from general computing

%%\subsection{Hypervisor security}
%%``Reflections on Trusting Trust'' by Kevin Thompson \cite{thompson1984reflections}

%%Hardware backdoors \cite{sparks2009chipset, duflot2010limits}

%%Reverse engineering requirement
%%\cite{rutkowska2008bluepilling}
%%In this section we shall provide a cursory review of the current state of affairs in technical solutions as implemented, or to be implemented, by some of the cloud storage providers out there.

%%\subsection{Case study: private cyberlocker}
%%\label{sec:cyberlocker}
%%How MEGA/Megaupload tried to cover themselves (and to a lesser extent their users) from the burden of accountability for the data they host
%%
%%Our ideas to keep private data private in cloud storage without sacrificing de-duplication
%%(subject to further experimentation)
%Following the disturbance in the cyberlocker ecosystem following the seizure of MegaUpload there has been growing interest in secure private cyberlocker services.
%This seems like a win-win situation for privacy: the cyberlocker sites have plausible deniability with respect to the content they are hosting, and their users can feel secure about their data privacy.
%We must ask ourselves why there is no true openness from any such providers of note to be found in the literature or when surfing the web. \cite{borgmann2012security}
%We have, however, tried to find out what we can from public sources about two newcomers to the scene.

%%In the market of so-called `cyberlocker' sites most don't use (or boast) any privacy enhancing technologies, and  those that do are not always open about their workings.
%MEGA and SpiderOak are both open about the fact that they make use of a layered approach whereby files are encrypted with strong random passwords, which are then encrypted by a single master password associated with the user.
%Assuming the underlying cipher and random generation algorithms are implemented in a cryptographically secure way such a scheme seems quite secure: neither the files nor their keys ever reach the server in the plain.
%Their approaches diverge when it comes to application delivery: where MEGA opted for in-browser delivery of content over the HTTPS channel SpiderOak chose to draft a native application for its service to better ensure application integrity (as it runs in a separate context).

%The SpiderOak client so far remains a closed-source application, but at least its code and behaviour can be audited and validated using traditional means.
%Compare this to MEGAs due to their choice of the web browser as a code delivery environment, which is much more tamper-prone due to its intended malleability by add-ons.
%An adversary that could manage to infect our browser through a malicious add-on (which is more likely to happen than infecting the host) would be able to intercept and modify our entire interaction with the MEGA service.

%Both of these services offer de-duplication, but SpiderOak makes sure to point out it does not do so across users because they apply \textit{personal encryption} to each file.
%As we understand it, this also describes MEGAs scheme: neither can do secure de-duplication across users without linking users to content, and therefore avoid doing so.

%But if MEGA truly has no idea of what users upload to their service, how should we read the headline ``Kim Dotcom Pulls 3D Printed Gun Plans from MEGA''~\cite{3d_gun}.

%\subsection{Past attacks}
%Past security vulnerabilities (that threaten privacy)
%\cite{meer2009clobbering}

\section{Privacy-Enhancing Technologies}
\label{sec:pet}

Our worries surrounding illegal wiretapping makes the more general, commercial side of our legal considerations seem somewhat moot.
What good is a strong system of privacy when it can be circumvented not only by member states of the European Council, but also the ostensibly most powerful intelligence agencies on the planet could permit itself to dive into our data.
The legal protection we enjoy is a nice-to-have, but in light of these concerns we must enforce our privacy by technical means if we take the adversary seriously.

%We would like to note that when applying the sort of the solutions we describe in \autoref{sec:pet} we process significantly less personal data.
Say, for instance, that we have a situation in which we want to search in a database.
Now, if we apply techniques to search using encrypted queries in an encrypted database, we stop processing any personal data that is not linked to the communications protocol (like IP addresses). Such techniques, are in a way a win-win solution. They reduce liability risks for providers and provide privacy for users.


Literature suggests a few alternatives to placing trust in a single third party, such as:
\begin{itemize}
\item \textit{server-aided cryptography}, where a third party server does some `heavy lifting' for its clients without having access to their secrets;
\item the as of yet underdeveloped notion of \textit{information-centric security}, where data is self-describing and self-defending, regardless of the context; \cite{chow2009controlling}
\item establishing trust by \textit{consensus} among a number of peers;
\item the still-developing field of \textit{Fully Homomorphic Encryption}, which would allow computations to be applied to data that \textit{remains under encryption}.
\end{itemize}

Certain recent technologies provide ways to interface with cloud services with some measure of privacy.
Two of these privacy-enhancing technologies are \emph{search under encryption} and \emph{reusable garbled secrets through functional encryption}.
Both come from the realm of cryptography and it should be noted that it is likely that encryption is never enough to provide privacy in the general case of cloud applications \cite{van2010impossibility}.
However, we feel that these two technologies can help in protecting the privacy of the user of cloud services.

\subsection{Searchable Encryption}

One application of particular interest in cloud computing setting is that of search.
It is not hard to imagine that, in a world where we store more and more data in the cloud, we would like good, secure and safe ways to search through said data.
However, we may not trust the cloud provider with knowing what we are searching for nor what sort of data is stored.
Enter searchable encryption, a scheme where both the stored data and the queries are kept secret.
In this section, we shall describe a fairly simple system of searchable encryption as devised by Boneh \cite{boneh2004public} called Public-Key Encryption with Keyword Search (PEKS).

Conceptually, PEKS is very simple:
Say people send Alice messages that are stored in some database.
These messages are constructed as follows:
given an encrypted message $msg$ containing words $w \in msg$, append to the encryption of $msg$ the PEKS encryptions of $w$ under the public key of the Alice.
The PEKS encryption works by having a separate keypair for each word $w$, the total of all of the public keys form the final public key of Alice, and the total of the private keys  from the final private key in the same manner. The encryption then returns a tuple containing some random value $M$ and the encryption of $M$ under the private key corresponding to $w$.
Finally, if Alice wants to query the message database, she constructs a trapdoor which is simply the private key corresponding with the word $w$ the wants to query for.
An algorithm that tests for the existence of the keyword gets such a tuple and a trapdoor and attempts to decrypt the second part of the tuple using the trapdoor until the decryption matches the first element of the tuple.
If this happens for a word belonging to a message, the message contains the word. 
In this, slightly simplified, version of the scheme, we cannot guarantee chosen-ciphertext security although modified versions may actually provide such a guarantee.
Also, performance is quite bad due to the massive amounts of public key operations (and even generation) going on in this scheme.

Note that Boneh would go on to provide some better solutions in \cite{boneh2007public}, but we shall not discuss those here.
Also, research has been done \cite{li2010fuzzy} on providing fuzzy keyword searching, i.e., when searching for ``foo'' we actually want to search for all keywords corresponding to ``*f*o*o*'', where * is the wildcard character.


% Only store encrypted data, Let clients perform crypto so it can be validated externally
% \cite{kamara2010cryptographic}

% Homomorphic encryption,
% Searching in encrypted data \cite{harrower2009searching, li2010fuzzy}

\subsection{Reusable Garbled Circuits}

Goldwasser \cite{goldwasser2013reusable} recently provided the means to reuse so-called garbled circuits by means of a functional encryption scheme using \emph{succinct} functions.
This allows the computation of succinct functions on encrypted data without learning anything but the result of the function.
To reuse Goldwasser's example, this allows us to, say, compute a spam-detection function on encrypted mail that learns nothing about the contents of said mail except whether it was classified as spam.
We shall not go into the details of the security properties of this system but we shall attempt to indicate how they work.

Essentially, a garbled circuit allows computation of a given function $f(x)$ without leaking information about $f$ or $x$.
The only information learned is the output, $f(x)$.
More precisely, we have a circuit $C$ that computes the respective function given input $x$.
We garble the circuit by encoding it using some one-way function, this outputs the garbled circuit $C'$ and a secret key $sk$.
The input $x$ is also encoded in order to fit the newly generated circuit.
These circuits basically need to provide two things: the privacy of $x$ and the privacy of $C$ (input privacy and circuit privacy, respectively).
Historically, such a garbled circuit was for one-time use only, new input required new encodings.
What Goldwasser did is to provide a way to, with only one key and thus one encoding, apply the circuit to a polynomial number of inputs.

As stated, in order to reuse such circuits we need a function encryption (FE) scheme.
In such a scheme, we have a master public key $mpk$ that anyone can encrypt data with.
Furthermore, the data owner can issue keys for functions that given a key $sk_f$ and ciphertext $c$ corresponding to input $x$ can compute $f(x)$ on $c$ using $sk_f$.
In this case we rely on homomorphic encryption to make sure that we can actually compute on encrypted data in a semantically secure way.

Now that the components are laid out, we shall go on to describe, very globally, the workings of Goldwasser's reusable garbled circuits.
As mentioned, we use fully homomorphic encryption (FHE) in order to compute on encrypted data.
The security of FHE guarantees no information leaks on the input $x$, therefore providing the input privacy that we need.
We now use a functional encryption scheme using FHE to compute functions $f$ on given input.
Still lacking is the ability to provide circuit privacy.
In Goldwasser's scheme, this is accomplished by garbling circuit $C$ using a semantically secure encryption scheme in combination with said functional encryption scheme.
This yields the garbled circuit $U$ and a secret key for $U$ such that given $sk$ and $x$, U will decrypt $C$ and yields $C(x)$.
In this scheme, we can reuse the circuit for a polynomial amount of inputs.

For a precise definition of the functional encryption scheme used and the reusable garbled circuit that follows we refer the reader to Goldwasser's excellent paper; this section was only intended as a global overview.

Given such a scheme as this, how does it apply to our particular use case?
In a cloud setting we can think of several services being given keys for functions corresponding to the service they provide.
All these services could operate on any data encrypted with the master public key, regardless of origin.
One such service might provide search functionality, as described in the previous section;
another might provide some consistency check of the underlying plaintext data;
yet another may generate statistics over some collection of encrypted data.

\section{Conclusion}
\label{sec:conclusion}

Cloud computing is still becoming increasingly more popular and thus making sure we ``do it right'' becomes more important as well.
In this paper we have attempted to provide an overview of the problems, both legal and technical, surrounding privacy and cloud computing as well as an overview of the current situation with modern cloud providers.
Furthermore, we have described two privacy-enhancing technologies, searchable encryption and reusable garbled circuits.
The latter being a very generic approach to applying functions to encrypted data, the former being a solution to a specific problem, i.e., searching encrypted data.
At the time of writing this paper, both solutions are likely infeasible to implement on any serious scale due to the performance issues associated with them.
However, we can hope that Moore's law in combination with bleeding-edge research can alleviate this pain some time in the future.

On a more personal note, we feel that the legal framework in Europe, especially considering the new and improved data protection regulation, is among the best in the world. We hope that sanity prevails in the face of over 2000 amendments to said regulation.

Concluding, we like to emphasize through repetition that doing cloud computing privacy right is very, very important lest we succumb to the generally upheld belief that privacy is dead. \textbf{It does not have to be}.

%\section{References}

\bibliography{Cloud_Privacy}{}
\bibliographystyle{unsrt}

\end{document}

% vim:tw=0:wrap

