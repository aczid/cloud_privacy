\documentclass[11pt]{article}
\usepackage{enumitem}
\usepackage{listings}
\usepackage{color}
\usepackage{tabularx}

\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{sidecap}
\usepackage{epstopdf}

%\def\bibfont{\scriptsize}

\usepackage{natbib}
\setlength{\bibsep}{0.0pt}

\begin{document}
\title{Privacy in Cloud Computing}

\author{Erik Boss \and Aram Verstegen}
%\institute{Radboud Universiteit Nijmegen}
\date{\today}
\maketitle

%\begin{abstract}
%\end{abstract}

\section{Introduction}
In recent years there has been a lot of positive buzz surrounding the idea of \textit{cloud computing}: a systems design trend that allows applications to run as ubiquitous services by providing abstractions to the lower layers of application architecture.
These layers can be distinguished as \textit{Software}, \textit{Platform} and \textit{Infrastructure} and each of these has a different target audience which can buy these facilities ``as a service'', i.e., Software/Platform/Infrastructure as a Service (SaaS, PaaS, IaaS). 
Such abstractions bring benefits like implicit redundancy, centralized security measures and, most importantly, reduces capital and operational expenses for customers by the increased efficiency at which each layer can be managed.

That being said, there is also a note of concern with things like centralized information management, giving up physical segregation for logical segregation, near-infinite storage capacity, cheap, ubiquitous computing power and the legal issues surrounding information processing systems whose infrastructure scale transcends national borders.

In cloud computing it's apparent that there is a very strong connection between security and privacy.
If any central component of cloud infrastructure were to be compromised it could almost certainly be used to disclose very privacy-sensitive information, given the scale of cloud infrastructure providers and what kind of private information is (or can be) recorded using applications running ``in the cloud''. In fact, there is no proof or technically feasible way to prove that such a compromise hasn't occurred.

In this paper we will go over some of the potential and actual privacy-related problems we have encountered as part of our study on the technical and legal domains of cloud computing. Starting off, in \autoref{sec:problems_in_cloud_computing} we shall give a fairly broad overview of the issues involved with cloud computing.
This will lead into an analysis of the current legal situation regarding cloud computing in \autoref{sec:legal_analysis}. In \autoref{sec:pet} and \autoref{sec:technical_analysis} we will go over the technical situation, specifically describing some of the solutions to privacy-related problems in cloud computing by means of Privacy Enhancing Techologies (PETs).

\section{Privacy problems in cloud computing}
\label{sec:problems_in_cloud_computing}
%General concerns with cloud security: centralisation, single point of failure, corporate espionage, subpoenas to the provider, impact of security compromises
%In the multi-layered design of cloud-based infrastructure our privacy concerns are mostly contained within individual layers.

While centralization of infrastructure should generally imply better basic physical and network security, it may lead to greater fragility of the networked ecosystem as a whole, whereby attacks have greater impact than in a strictly distributed environment.
Consider how acts of observation, manipulation or destruction would be more effective when carried out against the central node in a star-shaped network rather than anywhere in a well-connected network.
There exists more redundancy in the more connected network, which helps make the infrastructure more robust against any such disruptions.
%For a trustworthy internet we want to have more connection points into the network than the adversary can conceivably take over.
%Some systems may appear to be more (logically) distributed than they actually (physically) are. 

The main concern in related research is surrounding data privacy, but we find computational privacy to be of equal or greater concern.
Remotely hosted applications come with the inherent problem that their behaviour can be more difficult to analyse in order asses their security and privacy safeguards.
Whereas with personal computing the integrity of the system can be verified all the way down to the hardware level, the cloud environment requires trust in providers' ability to adequately handle privacy-sensitive information.
The problem is exacerbated by the fact that virtualization technologies abstract systems from the hardware layer, and require systems built upon them to similarly trust this technology during computation.
And again there is centralization in these technologies, leading to concerns about (virtually) universal backdoors in all systems built upon a handful of such technologies.
Literature suggests the as of yet underdeveloped notion of \textit{information-centric security}, where data is self-describing and self-defending, regardless of the context. \cite{chow2009controlling}

%We want to cover either of these two cases:

% Dit heeft eigenlijk niks met cloud privacy te maken... NSLs mogen alleen transactionele data opvragen
%\subsection{Problem case summary: Doe vs Ashcroft}
%In the United States there exists an investigative tool
%An investigative tool for intelligence agencies like the FBI known to be in use since 1978 is the National Security Letter (NSL): a demand letter for transactional records, accompanied by an indefinite gag order forbidding disclosure of the demand.
%Summary of the story of an ISP that got a NSL - and what an NSL actually demands
%\cite{garlinger2009privacy, gorham2008national}

%\subsection{Problem case summary: Cyberlocker raids}
%How cloud providers are being held accountable for the content they host

%\subsection{The dawn of personal cloud storage privacy}
% TODO how many providers to list?
Cloud providers like MediaFire, 4shared and the former MegaUpload provide a personal storage platform through the web for file sharing and archiving, be it public or private.
Such services, known as `cyberlockers' have become popular over the past decade or so, to the point where they can be considered ubiquitous.
The larger of these websites have in fact become so popular that they are in the lead for most visited sites and are among the most significant global internet bandwidth users.
Sharing services like these are known to be used as trafficking vehicles for pirated copyrighted media as they can provide free storage in a way that in most cases can be used anonymously, and can even generate profit for the uploader.
One of such companies was the former MegaUpload: a company which had its assets seized by the United States Department of Justice in early 2012 on claims of illegal file sharing activity, in what is still unfolding as a particularly complex legal case.
The company has since reinvented itself as MEGA, providing the same services but boasting better privacy and security by using cryptographic methods to mask the stored data.
Following the (foreseen) legal prosecution, other companies like Ciphercloud and SpiderOak have also brought forth solutions to similar concerns.
While MEGA and SpiderOak seem to have taken a cue from the cryptography community and chose to be open about their design to their users, Ciphercloud have recently become the center of controversy after they tried to file a DMCA takedown notice against a StackExchange thread in which their cryptography was analyzed and consequently decimated~\cite{ciphercloud}.
% TODO source ciphercloud
Given the lack of provided open-source implementations, it still seems the cryptography argument is a bit of a hand-wave.
We have decided to summarize some issues regarding these new designs in \autoref{sec:cyberlocker}.


\section{Legal analysis}
\label{sec:legal_analysis}

In this section we will review the relevant legal aspects surrounding cloud computing. We shall focus on the European legal framework since it is the most extensive.

The key legislature is the EU Data Protection Directive 95/46/EC, which provides basic rights to consumers' data by obligating data collectors to uphold their right to privacy. \cite{directive199595}
This directive is based on seven key principles surrounding citizen privacy.
They are as follows:
\begin{itemize}
\item Data subjects should be given notice of collection;
\item Data should only be used for the purposes specified;
\item Data should not be disclosed without the subject's consent;
\item The data processors should uphold adequate security;
\item It should be disclosed to data subjects who is processing their information;
\item Data subjects should be allowed to access and update their data;
\item It should be possible to hold data collectors accountable to these principles.
\end{itemize}

This legislature is set to be succeeded by the General Data Protection Regulation, which amends the code to extend its reach beyond the EU, and applies everywhere information about EU citizens is collected.
It also mandates that data breaches must be reported to the Data Protection Authority, and stipulates serious fines for failure to comply.
Note, however, that this regulation is still under review and thus subject to change.

Complementary to the Data Protection Directive is the E-privacy Directive (Directive on Privacy and Electronic Communications), which also protects citizens from excessive data retention, spam e-mail and the use of tracking cookies without explicit consent.
This document spawned the much-debated ``Cookie law'' (Cookiewet) in the Netherlands.

In a cloud computing setting, the main legal problems boil down to two issues: accountability of non-EU companies and multi-tenancy of cloud applications. Essentially, the problems emerge from different users belonging to different jurisdicitions using a system that is possibly in yet another jurisdiction. Try enforcing anything when the user lives in Europe, accessing an Asian server of an American company. Problems aplenty, we should think.

The type of cloud system, i.e., ``the X in XaaS'', also has its part to play in the legal setting of cloud computing.
From IaaS (infrastructure) to SaaS (software), the responsibilities concerning privacy of provider and client change.
In an IaaS setting, the provider can only do so much to provide privacy safeguards.
The responsibilities lie primarily in providing availability of the infrastructure as well as providing hypervisor and physical security.
The client, however is responsible for building secure applications or platforms on top of this infrastructure.
In a SaaS setting, the provider needs to provide more guarantees.
A user needs to be sure that the software is adequately secured on infrastructure, platform and software level.
Obviously, in the PaaS setting the responsibilities lie somewhere halfway between IaaS and SaaS. The provider needs to provide a secure platform but it is the client's job to provide the necessary safeguards for any application built on top of this platform.

We like to note that, when applying the sort of the solutions we describe in \autoref{sec:pet} we process significantly less personal data. Say, for instance, that we have a situation in which we want to search in a database. Now, if we apply techniques to search using encrypted queries in an encrypted database, we stop processing any personal data that is not linked to the communications protocol (like IP addresses). Such techniques, are in a way a win-win solution. They reduce liability risks for providers and provide privacy for users.

As a side note, the United States Department of Commerce has worked with the EU to develop the Data Protection Directive principles into what they call ``Safe Harbor'' principles which US companies can opt-in to.
This essentially allowed US companies to do business with the EU, which has the more stringent data protection legislation.
Also, the Digital Millennium Copyright Act (DMCA) recognizes the concept of a ``mere conduit'' (of information) as did the European Data Protection Directive. \cite{congress1998digital}
It should be noted that, currently, the protections the EU legislation provides do not extend beyond its borders.
Even after the new legislation comes into effect, the PATRIOT act~\cite{mailman2002uniting} still allows the United States to demand access to any businesses that operate there in the interest of national security.

% In hindsight, doing contract law was probably a bad idea, except for the auditing standards mentioned above..
% \subsection{Contract law}
% SLAs and how undesirable some of their provisions are


% Article 29 WP opinion (draft, nog geen reference)

%\subsection{Case law}
%Lindqvist case

% Legal responsibilities as a function of the type of cloud architecture (see slides for the idea)

\section{Current State of Affairs}
\label{sec:technical_analysis}
%Security considerations in cloud infrastructure

%Summary of techniques for security, focussing on Confidentiality and Integrity as we know them from general computing

%\subsection{Hypervisor security}
%``Reflections on Trusting Trust'' by Kevin Thompson \cite{thompson1984reflections}

%Hardware backdoors \cite{sparks2009chipset, duflot2010limits}

%Reverse engineering requirement
%\cite{rutkowska2008bluepilling}
In this section we shall provide a cursory review of the current state of affairs in technical solutions as implemented, or to be implemented, by some of the cloud storage providers out there.

\subsection{Case study: private cyberlocker}
\label{sec:cyberlocker}
%How MEGA/Megaupload tried to cover themselves (and to a lesser extent their users) from the burden of accountability for the data they host
%
%Our ideas to keep private data private in cloud storage without sacrificing de-duplication
%(subject to further experimentation)
Following the disturbance in the cyberlocker ecosystem following the seizure of MegaUpload there has been growing interest in secure private cyberlocker services.
This seems like a win-win situation for privacy: the cyberlocker sites have plausible deniability with respect to the content they are hosting, and their users can feel secure about their data privacy.
We must ask ourselves why there is no true openness from any such providers of note to be found in the literature or when surfing the web. \cite{borgmann2012security}
We tried to find out what we can from public sources about two newcomers to the scene.

%In the market of so-called `cyberlocker' sites most don't use (or boast) any privacy enhancing technologies, and  those that do are not always open about their workings.
MEGA and SpiderOak are both open about the fact that they make use of a layered approach whereby files are encrypted with strong random passwords, which are then encrypted by a single master password associated to the user.
Assuming the underlying cipher and random generation algorithms are implemented in a cryptographically secure way such a scheme seems quite secure: neither the files nor their keys ever reach the server in the plain.
Their approaches diverge when it comes to application delivery: where MEGA opted for in-browser delivery of content over the HTTPS channel SpiderOak chose to draft a native application for its service to better ensure application integrity (as it runs in a separate context).

The SpiderOak client so far remains a closed-source application, but at least its code and behaviour can be audited and validated using traditional means in contrast to MEGAs due to their choice of the web browser as a code delivery environment, which is much more tamper-prone due to its intended malleability by add-ons.
An adversary that could manage to infect our browser through a malicious add-on (which is more likely to happen than infecting the host) would be able to intercept and modify our entire interaction with the MEGA service.

Both of these services offer de-duplication, but SpiderOak makes sure to point out it doesn't do so across users because they apply \textit{personal encryption} to each file.
As we understand it, this also describes MEGAs scheme: neither can do secure de-duplication across users without linking users to content, and therefore avoid doing so.

But if MEGA truly has no idea of what users upload to their service, how should we read the headline ``Kim Dotcom Pulls 3D Printed Gun Plans from MEGA''~\cite{3d_gun}.

%\subsection{Past attacks}
%Past security vulnerabilities (that threaten privacy)
%\cite{meer2009clobbering}

\section{Privacy-Enhancing Technologies}
\label{sec:pet}

Certain recent technologies provide ways to interface with cloud services with some measure of privacy.
Two of these privacy-enhancing technologies are \emph{search under encryption} and \emph{reusable garbled secrets through function encryption}.
Both come from the realm of cryptography and it should be noted that it is likely that encryption is never enough to provide privacy in the general case of cloud applications \cite{van2010impossibility}.
However, we feel that these two technologies can help in protecting the privacy of the user of cloud services.

\subsection{Searchable Encryption}

One application of particular interest in cloud computing setting is that of search.
It is not hard to imagine that, in a world where we store more and more data in the cloud, we would like good, secure and safe ways to search through said data.
However, we may not trust the cloud provider with knowing what we are searching for nor what sort of data is stored.
Enter searchable encryption, a scheme where both the stored data and the queries are kept secret.
In this section, we shall describe a fairly simple system of searchable encryption as devised by Boneh \cite{boneh2004public} called Public-Key Encryption with Keyword Search (PEKS).

Conceptually, PEKS is very simple:
Say people send Alice messages that are stored in some database.
These messages are constructed as follows:
given an encrypted message $msg$ containing words $w \in msg$, append to the encryption of $msg$ the PEKS encryptions of $w$ under the public key of the Alice.
The PEKS encryption works by having a separate keypair for each word $w$, the total of all of the public keys form the final public key of Alice, and the total of the private keys  from the final private key in the same manner. The encryption then returns a tuple containing some random value $M$ and the encryption of $M$ under the private key corresponding to $w$.
Finally, if Alice wants to query the message database, she constructs a trapdoor which is simply the private key corresponding with the word $w$ the wants to query for.
An algorithm that tests for the existence of the keyword gets such a tuple and a trapdoor and attempts to decrypt the second part of the tuple using the trapdoor until the decryption matches the first element of the tuple.
If this happens for a word belonging to a message, the message contains the word. 
In this, slightly simplified, version of the scheme, we cannot guarantee chosen-ciphertext security although modified versions may.
Also, performance is quite bad due to the massive amounts of public key operations (and even generation) going on in this scheme.

Note that Boneh would go on to provide some better solutions in \cite{boneh2007public}, but we shall not discuss those here.
Also, research has been done \cite{li2010fuzzy} on providing fuzzy keyword searching, i.e., when searching for ``foo'' we actually want to search for all keywords corresponding to ``*f*o*o*'', where * is the wildcard character.


% Only store encrypted data, Let clients perform crypto so it can be validated externally
% \cite{kamara2010cryptographic}

% Homomorphic encryption,
% Searching in encrypted data \cite{harrower2009searching, li2010fuzzy}

\subsection{Reusable Garbled Circuits}

Goldwasser \cite{goldwasser2013reusable} recently provided the means to reuse so-called garbled circuits by means of a functional encryption scheme using \emph{succinct} functions.
This allows the computation of succinct functions on encrypted data without learning anything but the result of the function.
To reuse Goldwasser's example, this allows us to, say, compute a spam-detection function on encrypted mail that learns nothing about the contents of said mail except whether it was classified as spam.
We shall not go into the details of the security properties of this system but we shall attempt to indicate how they work.

Essentially, a garbled circuit allows computation of a given function $f(x)$ without leaking information about $f$ or $x$.
The only information learned is the output, $f(x)$.
More precisely, we have a circuit $C$ that computes the respective function given input $x$.
We garble the circuit by encoding it using some one-way function, this outputs the garbled circuit $C'$ and a secret key $sk$.
The input $x$ is also encoded in order to fit the newly generated circuit.
These circuits basically need to provide two things: the privacy of $x$ and the privacy of $C$ (input privacy and circuit privacy, respectively).
Historically, such a garbled circuit was for one-time use only, new input required new encodings.
What Goldwasser did is to provide a way to, with only one key and thus one encoding, apply the circuit to a polynomial number of inputs.

As stated, in order to reuse such circuits we need a function encryption (FE) scheme.
In such a scheme, we have a master public key $mpk$ that anyone can encrypt data with.
Furthermore, the data owner can issue keys for functions that given a key $sk_f$ and ciphertext $c$ corresponding to input $x$ can compute $f(x)$ on $c$ using $sk_f$.
In this case we rely on homomorphic encryption to make sure that we can actually compute on encrypted data in a semantically secure way.

Now that the components are laid out, we shall go on to describe, very globally, the workings of Goldwasser's reusable garbled circuits.
As mentioned, we use fully homomorphic encryption (FHE) in order to compute on encrypted data.
The security of FHE guarantees no information leaks on the input $x$, therefore providing the input privacy that we need.
We now use a functional encryption scheme using FHE to compute functions $f$ on given input.
Still lacking is the ability to provide circuit privacy.
In Goldwasser's scheme, this is accomplished by garbling circuit $C$ using a semantically secure encryption scheme in combination with said functional encryption scheme.
This yields the garbled circuit $U$ and a secret key for $U$ such that given $sk$ and $x$, U will decrypt $C$ and yields $C(x)$.
In this scheme, we can reuse the circuit for a polynomial amount of inputs.

For a precise definition of the functional encryption scheme used and the reusable garbled circuit that follows we refer the reader to Goldwasser's excellent paper; this section was only intended as a global overview.

Given such a scheme as this, how does it apply to our particular use case?
In a cloud setting we can think of several services being given keys for functions corresponding to the service they provide.
All these services could operate on any data encrypted with the master public key, regardless of origin.
One such service might provide search functionality, as described in the previous section;
another might provide some consistency check of the underlying plaintext data;
yet another may generate statistics over some collection of encrypted data.



\section{Conclusion}

Cloud computing is still becoming increasingly more popular and thus making sure we ``do it right'' becomes more important as well.
In this paper we have attempted to provide an overview of the problems, both legal and technical, surrounding privacy and cloud comupting as well as an overview of the current situation with modern cloud providers.
Furthemore, we have described two privacy-enhancing technologies, searchable encryption and reusable garbled circuits.
The latter being a very generic approach to applying functions to encrypted data, the former being a solution to a specific problem, i.e., searching encrypted data.
At the time of writing this paper, both solutions are likely infeasible to implement on any serious scale due to the performance issues associated with them.
However, we can hope that Moore's law in combination with bleeding-edge research can alleviate this pain some time in the future.

On a more personal note, we feel that the legal framework in Europe, especially considering the new and improved data protection regulation, is among the best in the world. We hope that sanity prevails in the face of over 2000 amendments to said regulation.

All that said, we conclude in repeating that doing cloud computing privacy right is very, very important lest we succumb to the general notion that privacy is dead. It does not have to be.

%\section{References}

\bibliography{Cloud_Privacy}{}
\bibliographystyle{unsrt}

\end{document}

% vim:tw=0:wrap

